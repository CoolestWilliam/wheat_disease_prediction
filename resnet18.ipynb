{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "id": "iXNFDHZxCuqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import timm\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "from torchvision import datasets, transforms\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "CuvaA417DUlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nmweg2Z4Cj04"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_path = \"/content/drive/My Drive/wheat_data.zip\""
      ],
      "metadata": {
        "id": "9TKK4rN0C7pU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_path = \"/content/wheat_data\"\n",
        "\n",
        "# Unzip the dataset\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "      zip_ref.extractall(extract_path)\n",
        "\n",
        "# Check it's there\n",
        "print(os.listdir(extract_path))"
      ],
      "metadata": {
        "id": "zDHZIOxpSxss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "^ 3 min to run"
      ],
      "metadata": {
        "id": "6gseVXD0VLKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "base_path = \"/content/wheat_data/wheat_data\"  # Fixed path\n",
        "\n",
        "train_dir = os.path.join(base_path, \"train\")\n",
        "valid_dir = os.path.join(base_path, \"valid\")\n",
        "test_dir  = os.path.join(base_path, \"test\")\n",
        "\n",
        "\n",
        "# Datasets\n",
        "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
        "valid_dataset = datasets.ImageFolder(valid_dir, transform=transform)\n",
        "test_dataset  = datasets.ImageFolder(test_dir,  transform=transform)\n",
        "\n",
        "# Loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ],
      "metadata": {
        "id": "9fR5_RDADYn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, len(train_dataset.classes))\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "ZBYpTznQKKyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "0dmkxkyhXDLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Early stopping setup\n",
        "best_val_loss = float('inf')\n",
        "patience = 3\n",
        "counter = 0"
      ],
      "metadata": {
        "id": "k20q6dhZODlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "best_val_loss = float('inf')\n",
        "patience = 5\n",
        "counter = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\", leave=False)\n",
        "    for images, labels in loop:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        loop = tqdm(valid_loader, desc=f\"Epoch {epoch+1}/{epochs} [Val]\", leave=False)\n",
        "        for images, labels in loop:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            loop.set_postfix(val_loss=loss.item())\n",
        "\n",
        "    val_loss /= len(valid_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch+1} - Train Loss: {train_loss:.4f} - Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "    # Early stopping logic (no saving)\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        counter = 0\n",
        "    else:\n",
        "        counter += 1\n",
        "        print(f\"Early stopping patience: {counter}/{patience}\")\n",
        "        if counter >= patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break"
      ],
      "metadata": {
        "id": "j53V9xHTXADS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model evaluation"
      ],
      "metadata": {
        "id": "H-lZyzSf0GOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "# set model to evaluation mode\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in tqdm(test_loader, desc=\"Evaluating on Test Set\"):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "test_accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "WA-OZ8JXz-Z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report"
      ],
      "metadata": {
        "id": "-Wmr2xba0H1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "model.eval()\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "class_correct = defaultdict(int)\n",
        "class_total = defaultdict(int)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in tqdm(test_loader, desc=\"Evaluating for Confusion Matrix\"):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        for label, pred in zip(labels, predicted):\n",
        "            class_total[label.item()] += 1\n",
        "            if label == pred:\n",
        "                class_correct[label.item()] += 1"
      ],
      "metadata": {
        "id": "zsOSkrwV0IVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report_dict = classification_report(\n",
        "    all_labels,\n",
        "    all_preds,\n",
        "    target_names=train_dataset.classes,\n",
        "    output_dict=True,\n",
        "    zero_division=0\n",
        ")"
      ],
      "metadata": {
        "id": "-AkPcpnN0m3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert report dict to DataFrame\n",
        "metrics_df = pd.DataFrame(report_dict).transpose()\n",
        "\n",
        "# Keep only class rows (filter out 'accuracy', 'macro avg', etc.)\n",
        "metrics_df = metrics_df.loc[train_dataset.classes]\n",
        "\n",
        "# Round for readability\n",
        "metrics_df = metrics_df.round(2)\n",
        "\n",
        "# Print the DataFrame\n",
        "print(metrics_df)"
      ],
      "metadata": {
        "id": "IiiOSA_e0pur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store results in a list of dictionaries\n",
        "accuracy_data = []\n",
        "\n",
        "for idx, class_name in enumerate(train_dataset.classes):\n",
        "    accuracy = 100 * class_correct[idx] / class_total[idx] if class_total[idx] > 0 else 0.0\n",
        "    accuracy_data.append({\n",
        "        \"Class\": class_name,\n",
        "        \"Accuracy (%)\": round(accuracy, 2),\n",
        "        \"Correct\": class_correct[idx],\n",
        "        \"Total\": class_total[idx]\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame\n",
        "accuracy_df = pd.DataFrame(accuracy_data)\n",
        "\n",
        "# Print the DataFrame\n",
        "print(accuracy_df)\n"
      ],
      "metadata": {
        "id": "RI5vLK1g0NfC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}