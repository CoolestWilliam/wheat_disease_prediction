# -*- coding: utf-8 -*-
"""MobileNetV2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RtGBl--p7xe9cm_TBHtWgeXUSE-iHPoB
"""

# === Imports ===
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Model
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from collections import defaultdict
import numpy as np
import os

# === Mount Google Drive ===
from google.colab import drive
drive.mount('/content/drive')

# === Set paths ===
base_path = '/content/drive/MyDrive/wheat_data'
train_path = os.path.join(base_path, 'train')
val_path = os.path.join(base_path, 'valid')
test_path = os.path.join(base_path, 'test')

# === Image settings ===
IMG_SIZE = (224, 224)  # MobileNetV2 default
BATCH_SIZE = 32
EPOCHS = 5  # You can increase to 10â€“15 if accuracy improves

# === Data generators ===
datagen = ImageDataGenerator(rescale=1./255)

train_gen = datagen.flow_from_directory(
    train_path, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical', shuffle=True
)

val_gen = datagen.flow_from_directory(
    val_path, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical', shuffle=False
)

test_gen = datagen.flow_from_directory(
    test_path, target_size=IMG_SIZE, batch_size=1, class_mode='categorical', shuffle=False
)

# === Build MobileNetV2 model ===
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(128, activation='relu')(x)
predictions = Dense(train_gen.num_classes, activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=predictions)

# === Freeze base model layers (transfer learning) ===
for layer in base_model.layers:
    layer.trainable = False

# === Compile and train ===
model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])

model.fit(train_gen, validation_data=val_gen, epochs=EPOCHS, verbose=1)

# === Predict on test set ===
test_gen.reset()
y_pred_probs = model.predict(test_gen, verbose=1)
y_pred = np.argmax(y_pred_probs, axis=1)
y_true = test_gen.classes

# === Clean folder names like 'aphid_test' to 'Aphid' ===
def clean_class_name(name):
    return name.replace('_test', '').replace('_valid', '').replace('_train', '').replace('_', ' ').title()

true_class_names = [clean_class_name(name) for name in test_gen.class_indices.keys()]

# === Accuracy report ===
correct_per_class = defaultdict(int)
total_per_class = defaultdict(int)

for i in range(len(y_true)):
    true_class = y_true[i]
    pred_class = y_pred[i]
    class_name = true_class_names[true_class]
    total_per_class[class_name] += 1
    if pred_class == true_class:
        correct_per_class[class_name] += 1

# === Print results table ===
print(f"\n{'Class':<30}{'Accuracy (%)':<15}{'Correct':<10}{'Total'}")
for class_name in sorted(true_class_names):
    correct = correct_per_class[class_name]
    total = total_per_class[class_name]
    acc = (correct / total * 100) if total > 0 else 0
    print(f"{class_name:<30}{acc:<15.1f}{correct:<10}{total}")

# === Imports ===
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Model
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from collections import defaultdict
import numpy as np
import os

# === Mount Google Drive (optional) ===
from google.colab import drive
drive.mount('/content/drive')

# === Set paths ===
base_path = '/content/drive/MyDrive/wheat_data'  # adjust if not using Colab
train_path = os.path.join(base_path, 'train')
val_path = os.path.join(base_path, 'valid')
test_path = os.path.join(base_path, 'test')

# === Image settings ===
IMG_SIZE = (224, 224)
BATCH_SIZE = 32
EPOCHS = 5  # Start small; increase later if performance improves

# === Data augmentation for training ===
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.1,
    height_shift_range=0.1,
    zoom_range=0.2,
    horizontal_flip=True,
    vertical_flip=True,
    brightness_range=[0.8, 1.2],
    fill_mode='nearest'
)

val_test_datagen = ImageDataGenerator(rescale=1./255)

# === Generators ===
train_gen = train_datagen.flow_from_directory(
    train_path, target_size=IMG_SIZE, batch_size=BATCH_SIZE,
    class_mode='categorical', shuffle=True
)

val_gen = val_test_datagen.flow_from_directory(
    val_path, target_size=IMG_SIZE, batch_size=BATCH_SIZE,
    class_mode='categorical', shuffle=False
)

test_gen = val_test_datagen.flow_from_directory(
    test_path, target_size=IMG_SIZE, batch_size=1,
    class_mode='categorical', shuffle=False
)

# === Build MobileNetV2 model ===
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(128, activation='relu')(x)
predictions = Dense(train_gen.num_classes, activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=predictions)

# === Freeze base layers for transfer learning ===
for layer in base_model.layers:
    layer.trainable = False

# === Compile model ===
model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])

# === Train model ===
model.fit(train_gen, validation_data=val_gen, epochs=EPOCHS, verbose=1)

# === Evaluate on test set ===
test_gen.reset()
y_pred_probs = model.predict(test_gen, verbose=1)
y_pred = np.argmax(y_pred_probs, axis=1)
y_true = test_gen.classes

# === Get readable class names ===
def clean_class_name(name):
    return name.replace('_test', '').replace('_valid', '').replace('_train', '').replace('_', ' ').title()

true_class_names = [clean_class_name(name) for name in test_gen.class_indices.keys()]

# === Compute per-class accuracy ===
correct_per_class = defaultdict(int)
total_per_class = defaultdict(int)

for i in range(len(y_true)):
    true_class = y_true[i]
    pred_class = y_pred[i]
    class_name = true_class_names[true_class]
    total_per_class[class_name] += 1
    if pred_class == true_class:
        correct_per_class[class_name] += 1

# === Print accuracy per class ===
print(f"\n{'Class':<30}{'Accuracy (%)':<15}{'Correct':<10}{'Total'}")
for class_name in sorted(true_class_names):
    correct = correct_per_class[class_name]
    total = total_per_class[class_name]
    acc = (correct / total * 100) if total > 0 else 0
    print(f"{class_name:<30}{acc:<15.1f}{correct:<10}{total}")

from sklearn.metrics import classification_report

# Use class names in the same order as test_gen.class_indices
class_labels = list(test_gen.class_indices.keys())

# Print precision, recall, F1-score
print(classification_report(y_true, y_pred, target_names=class_labels, digits=3))